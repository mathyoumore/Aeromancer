{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8540b10f",
   "metadata": {},
   "source": [
    "### Edit this so that it's the month you want to generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "502c5c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "month = 12\n",
    "\n",
    "# Do you only want the severe events?\n",
    "severe = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa111633",
   "metadata": {},
   "source": [
    "### Now hit the double right arrows in the menu above. The rest of this works on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "87729108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from re import search, sub\n",
    "from os import listdir \n",
    "\n",
    "def fill_or_swap_duplicates(final_df, new_df, column='nws_id'):\n",
    "    if len(final_df) == 0:\n",
    "        # If the final df is empty, fill it with the file's contents\n",
    "        return new_df\n",
    "    else:\n",
    "        # Otherwise, remove all column values the final df has in common with the new file\n",
    "        # and insert the newer values (assumes the files are in order).\n",
    "        # This assumes the files are in alphabetical order, so careful\n",
    "        result_df = final_df[~final_df[column].isin(new_df[column])]\n",
    "        return pd.concat([result_df, new_df])\n",
    "\n",
    "\n",
    "directory = 'test/'\n",
    "salt = None\n",
    "old_date, old_type = -1, None\n",
    "final_df, final_events_df, final_locations_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "ugc_df = pd.read_csv('ugc_master.csv')\n",
    "county_zip_df = pd.read_csv('zip_code_database.csv')\n",
    "county_cleaner = (\n",
    "    r\"(North[ews]\\w*|South[ews]\\w*|Eastern|Western|Central|Interior|Coastal|\"\n",
    "    r\"\\s?Inland|\\s?County|\\s?Borough|Mountains?|Gorge|Area|Slopes|Upper|Lower)\\s?\")\n",
    "\n",
    "file_matcher = (\n",
    "    r\"_(?P<year>20\\d{2})\"\n",
    "    r\"(?P<month>\\d{2})\"\n",
    "    r\"(?P<date>\\d{2})\"\n",
    "    r\"_(?P<hour>\\d{2}_)\"\n",
    "    r\"(?P<filetype>events|event_locations)\"\n",
    ")\n",
    "\n",
    "for file in sorted(listdir(directory)):\n",
    "    # Make sure it's a filename format we expect\n",
    "    # The result of this wille a dict with keys [year,month,date,hour,filetype]\n",
    "    try: \n",
    "        match_dict = search(file_matcher,file).groupdict()\n",
    "        if int(match_dict['year']) != year or int(match_dict['month']) != month:\n",
    "            print('Found a file outside of file format, skipping',file)\n",
    "    except:\n",
    "        print('Failed to parse file name, skipping',file)\n",
    "        continue\n",
    "    \n",
    "    # ensure the files are sorted\n",
    "    # fill_or_swap_duplicates assumes the more recently viewed file is newer, \n",
    "    # and therefore has the most up-to-date information\n",
    "    # So this ends up being important \n",
    "    match_dict['date'] = int(match_dict['date'])\n",
    "    \n",
    "    if old_date < 0:\n",
    "        old_date = match_dict['date'] - 1\n",
    "        old_type = match_dict['filetype']\n",
    "    \n",
    "    if old_type != match_dict['filetype'] and old_date == match_dict['date']:\n",
    "        old_type = match_dict['filetype']\n",
    "    elif old_date > match_dict['date']:\n",
    "        assert False, \"Files are not sorted! Files must be sorted alphanumerically.\"\n",
    "    \n",
    "    old_date = match_dict['date']\n",
    "    \n",
    "    filepath = directory + file \n",
    "    if match_dict['filetype'] == 'events':\n",
    "        event_file_df = pd.read_csv(filepath, \n",
    "                              parse_dates = [2,3], \n",
    "                              date_parser=lambda col: pd.to_datetime(col, utc=True))\n",
    "        final_events_df = fill_or_swap_duplicates(final_events_df, event_file_df)\n",
    "    elif match_dict['filetype'] == 'event_locations':\n",
    "        locations_file_df = pd.read_csv(filepath)\n",
    "        final_locations_df = fill_or_swap_duplicates(final_locations_df, locations_file_df)\n",
    "    else:\n",
    "        print(\"I dunno what to do with this:\",filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8ab0d087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_county</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>snow_min</th>\n",
       "      <th>snow_max</th>\n",
       "      <th>ice_min</th>\n",
       "      <th>ice_max</th>\n",
       "      <th>sleet_min</th>\n",
       "      <th>sleet_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37200</th>\n",
       "      <td>Oswego</td>\n",
       "      <td>NY</td>\n",
       "      <td>13028</td>\n",
       "      <td>2022-12-16 19:56:00+00:00</td>\n",
       "      <td>2022-12-17 03:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37201</th>\n",
       "      <td>Oswego</td>\n",
       "      <td>NY</td>\n",
       "      <td>13036</td>\n",
       "      <td>2022-12-16 19:56:00+00:00</td>\n",
       "      <td>2022-12-17 03:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37202</th>\n",
       "      <td>Oswego</td>\n",
       "      <td>NY</td>\n",
       "      <td>13042</td>\n",
       "      <td>2022-12-16 19:56:00+00:00</td>\n",
       "      <td>2022-12-17 03:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37203</th>\n",
       "      <td>Oswego</td>\n",
       "      <td>NY</td>\n",
       "      <td>13044</td>\n",
       "      <td>2022-12-16 19:56:00+00:00</td>\n",
       "      <td>2022-12-17 03:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37204</th>\n",
       "      <td>Oswego</td>\n",
       "      <td>NY</td>\n",
       "      <td>13069</td>\n",
       "      <td>2022-12-16 19:56:00+00:00</td>\n",
       "      <td>2022-12-17 03:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152703</th>\n",
       "      <td>Beaverhead</td>\n",
       "      <td>MT</td>\n",
       "      <td>59736</td>\n",
       "      <td>2022-12-19 21:39:00+00:00</td>\n",
       "      <td>2022-12-22 00:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152704</th>\n",
       "      <td>Beaverhead</td>\n",
       "      <td>MT</td>\n",
       "      <td>59739</td>\n",
       "      <td>2022-12-19 21:39:00+00:00</td>\n",
       "      <td>2022-12-22 00:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152705</th>\n",
       "      <td>Beaverhead</td>\n",
       "      <td>MT</td>\n",
       "      <td>59746</td>\n",
       "      <td>2022-12-19 21:39:00+00:00</td>\n",
       "      <td>2022-12-22 00:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152706</th>\n",
       "      <td>Beaverhead</td>\n",
       "      <td>MT</td>\n",
       "      <td>59761</td>\n",
       "      <td>2022-12-19 21:39:00+00:00</td>\n",
       "      <td>2022-12-22 00:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152707</th>\n",
       "      <td>Beaverhead</td>\n",
       "      <td>MT</td>\n",
       "      <td>59762</td>\n",
       "      <td>2022-12-19 21:39:00+00:00</td>\n",
       "      <td>2022-12-22 00:00:00+00:00</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Winter Storm Warning</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98578 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clean_county state    zip                     start  \\\n",
       "37200        Oswego    NY  13028 2022-12-16 19:56:00+00:00   \n",
       "37201        Oswego    NY  13036 2022-12-16 19:56:00+00:00   \n",
       "37202        Oswego    NY  13042 2022-12-16 19:56:00+00:00   \n",
       "37203        Oswego    NY  13044 2022-12-16 19:56:00+00:00   \n",
       "37204        Oswego    NY  13069 2022-12-16 19:56:00+00:00   \n",
       "...             ...   ...    ...                       ...   \n",
       "152703   Beaverhead    MT  59736 2022-12-19 21:39:00+00:00   \n",
       "152704   Beaverhead    MT  59739 2022-12-19 21:39:00+00:00   \n",
       "152705   Beaverhead    MT  59746 2022-12-19 21:39:00+00:00   \n",
       "152706   Beaverhead    MT  59761 2022-12-19 21:39:00+00:00   \n",
       "152707   Beaverhead    MT  59762 2022-12-19 21:39:00+00:00   \n",
       "\n",
       "                             end severity                  type  snow_min  \\\n",
       "37200  2022-12-17 03:00:00+00:00   Severe  Winter Storm Warning       2.0   \n",
       "37201  2022-12-17 03:00:00+00:00   Severe  Winter Storm Warning       2.0   \n",
       "37202  2022-12-17 03:00:00+00:00   Severe  Winter Storm Warning       2.0   \n",
       "37203  2022-12-17 03:00:00+00:00   Severe  Winter Storm Warning       2.0   \n",
       "37204  2022-12-17 03:00:00+00:00   Severe  Winter Storm Warning       2.0   \n",
       "...                          ...      ...                   ...       ...   \n",
       "152703 2022-12-22 00:00:00+00:00   Severe  Winter Storm Warning       3.0   \n",
       "152704 2022-12-22 00:00:00+00:00   Severe  Winter Storm Warning       3.0   \n",
       "152705 2022-12-22 00:00:00+00:00   Severe  Winter Storm Warning       3.0   \n",
       "152706 2022-12-22 00:00:00+00:00   Severe  Winter Storm Warning       3.0   \n",
       "152707 2022-12-22 00:00:00+00:00   Severe  Winter Storm Warning       3.0   \n",
       "\n",
       "        snow_max  ice_min  ice_max  sleet_min  sleet_max  \n",
       "37200        4.0      NaN      NaN        NaN        NaN  \n",
       "37201        4.0      NaN      NaN        NaN        NaN  \n",
       "37202        4.0      NaN      NaN        NaN        NaN  \n",
       "37203        4.0      NaN      NaN        NaN        NaN  \n",
       "37204        4.0      NaN      NaN        NaN        NaN  \n",
       "...          ...      ...      ...        ...        ...  \n",
       "152703      10.0      NaN      NaN        NaN        NaN  \n",
       "152704      10.0      NaN      NaN        NaN        NaN  \n",
       "152705      10.0      NaN      NaN        NaN        NaN  \n",
       "152706      10.0      NaN      NaN        NaN        NaN  \n",
       "152707      10.0      NaN      NaN        NaN        NaN  \n",
       "\n",
       "[98578 rows x 13 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are differences between the zip-county databae and the NWS' county identification \n",
    "# This reconciles most of them, the ones that aren't caught tend to be geographic-specific locations \n",
    "ugc_df['clean_county'] = ugc_df['name'].apply(lambda x: sub(county_cleaner,'',x).strip())\n",
    "\n",
    "# Build up a ugc-zip data table based on the UGCs we know so far \n",
    "ugc_zip = ugc_df.merge(\n",
    "    county_zip_df, \n",
    "    left_on=['state','clean_county'], \n",
    "    right_on=['state','clean_county'],\n",
    "    how='left')\n",
    "\n",
    "# Rename, filter out to just the columns we need\n",
    "ugc_zip = ugc_zip.rename(columns={'ugc_x':'ugc'})[['ugc','name','state','clean_county','zip','irs_estimated_population']]\n",
    "\n",
    "# Make a table that joins our event_locations to this zip database\n",
    "loc_zip = final_locations_df.merge(\n",
    "    ugc_zip,\n",
    "    left_on='ugc',\n",
    "    right_on='ugc')\n",
    "\n",
    "# Pandas assumes nothing about datatypes, so let's convert some stuff\n",
    "loc_zip['nws_id'] = loc_zip['nws_id'].astype(str)\n",
    "loc_zip['zip'] = loc_zip['zip'].astype('Int64')\n",
    "final_events_df['nws_id'] = final_events_df['nws_id'].astype(str)\n",
    "\n",
    "#One more gigantic merge \n",
    "prep_final_df = final_events_df.merge(\n",
    "    loc_zip, \n",
    "    on='nws_id')\n",
    "\n",
    "# Filter out events we don't have a zip for (because they're probably mountains or a gorge or whatever)\n",
    "# Then filter out lesser events if Severe is True, otherwise bring in everyone \n",
    "final_df = ( prep_final_df[(~prep_final_df['zip'].isna()) &\n",
    "                           (True if not(severe) else prep_final_df['severity'].isin(['Severe','Extreme']))]\n",
    "           )\n",
    "\n",
    "# Final columns \n",
    "print_df = final_df[[\n",
    "    'clean_county',\n",
    "    'state',\n",
    "    'zip',\n",
    "    'start',\n",
    "    'end',\n",
    "    'severity',\n",
    "    'type',\n",
    "    'snow_min',\n",
    "    'snow_max',\n",
    "    'ice_min',\n",
    "    'ice_max',\n",
    "    'sleet_min',\n",
    "    'sleet_max',  \n",
    "]]\n",
    "\n",
    "print_df.reset_index(drop=True).to_csv(\"data/reports/{}{}_adverse_weather_report.csv\".format(year,month),index=False)\n",
    "print_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
